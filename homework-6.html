<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Homework 6 ‚Äî Online Algorithms for Incremental Statistics</title>
  <link rel="stylesheet" href="style.css"/>
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;600;700&family=Orbitron:wght@600&display=swap" rel="stylesheet">
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        processRefs: true
      },
      svg: {
        fontCache: 'global',
        scale: 1
      },
      startup: {
        delay: 500,
        pageReady: () => {
          return MathJax.typesetPromise().catch(err => console.log(err));
        }
      }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    .hw-section {
      background: rgba(30,44,74,0.95);
      border-radius: 16px;
      margin: 2rem 0;
      padding: 2rem;
      box-shadow: 0 8px 32px rgba(24,224,230,0.15);
    }
    
    .step-container {
      background: rgba(20,32,66,0.6);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
      border-left: 4px solid #18e0e6;
    }
    
    .step-title {
      color: #18e0e6;
      font-weight: 600;
      font-size: 1.1rem;
      margin-bottom: 1rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }
    
    .step-number {
      background: #18e0e6;
      color: #0a1628;
      width: 28px;
      height: 28px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.9rem;
      font-weight: bold;
    }
    
    .explanation {
      background: rgba(15,25,55,0.7);
      border-radius: 8px;
      padding: 1.25rem;
      margin: 1rem 0;
      border-left: 3px solid #4a9eff;
      font-size: 0.95rem;
      line-height: 1.8;
    }

    .math-formula {
      background: rgba(8,15,35,0.95);
      border-radius: 10px;
      padding: 1.5rem;
      margin: 1rem 0;
      border-left: 3px solid #18e0e6;
      color: #e9f2ff;
      overflow-x: auto;
    }

    .formula-title {
      color: #18e0e6;
      font-weight: bold;
      margin-bottom: 1rem;
      font-size: 1.05rem;
    }

    .formula-content {
      color: #b8d4ff;
      line-height: 2;
      margin: 1rem 0;
      font-size: 1.05rem;
    }

    .formula-content ul {
      margin-left: 1.5rem;
      margin-top: 0.75rem;
      line-height: 1.9;
    }

    .comparison-box {
      background: rgba(24,224,230,0.08);
      border: 1px solid #18e0e6;
      border-radius: 10px;
      padding: 1.25rem;
      margin: 1rem 0;
    }

    .pros {
      background: rgba(76,175,80,0.1);
      border-left: 3px solid #4caf50;
      padding: 1rem;
      border-radius: 8px;
      margin: 0.75rem 0;
    }

    .cons {
      background: rgba(244,67,54,0.1);
      border-left: 3px solid #f44336;
      padding: 1rem;
      border-radius: 8px;
      margin: 0.75rem 0;
    }

    .pros h5 {
      color: #81c784;
      margin-top: 0;
      margin-bottom: 0.5rem;
    }

    .cons h5 {
      color: #ef5350;
      margin-top: 0;
      margin-bottom: 0.5rem;
    }

    .pseudocode {
      background: rgba(8,15,35,0.9);
      border: 1px solid #4a9eff;
      border-radius: 10px;
      padding: 1.5rem;
      margin: 1rem 0;
      font-family: 'Courier New', monospace;
      font-size: 0.95rem;
      color: #b8d4ff;
      overflow-x: auto;
      line-height: 1.8;
    }

    .pseudocode-title {
      color: #18e0e6;
      font-weight: bold;
      margin-bottom: 1rem;
    }

    .pseudocode-line {
      color: #b8d4ff;
      margin: 0.3rem 0;
    }

    .keyword {
      color: #ff9800;
      font-weight: bold;
    }

    .comment {
      color: #4caf50;
    }

    .interactive-tool {
      background: rgba(20,32,66,0.8);
      border: 2px solid #18e0e6;
      border-radius: 12px;
      padding: 2rem;
      margin: 2rem 0;
    }

    .tool-section {
      background: rgba(15,25,55,0.6);
      border-radius: 10px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }

    .tool-title {
      color: #18e0e6;
      font-weight: 600;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }

    .input-group {
      margin: 1rem 0;
    }

    .input-group label {
      display: block;
      color: #b8d4ff;
      margin-bottom: 0.5rem;
      font-weight: 500;
    }

    .input-group input,
    .input-group textarea,
    .input-group select {
      width: 100%;
      padding: 0.75rem;
      border-radius: 8px;
      border: 1px solid #3a5a8a;
      background: #0f1937;
      color: #e9f2ff;
      font-family: inherit;
      box-sizing: border-box;
      font-size: 0.95rem;
    }

    .input-group textarea {
      font-family: 'Courier New', monospace;
      min-height: 80px;
      resize: vertical;
    }

    .btn-group {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      margin: 1.5rem 0;
    }

    .btn {
      background: linear-gradient(135deg, #18e0e6 0%, #2bd4d9 100%);
      color: #0a1628;
      border: none;
      padding: 0.75rem 1.5rem;
      border-radius: 25px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s ease;
      font-size: 0.95rem;
    }

    .btn:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 15px rgba(24,224,230,0.3);
    }

    .btn:disabled {
      opacity: 0.5;
      cursor: not-allowed;
      transform: none;
    }

    .btn.secondary {
      background: linear-gradient(135deg, #4a9eff 0%, #6bb6ff 100%);
    }

    .btn.danger {
      background: linear-gradient(135deg, #ff5722 0%, #ff7043 100%);
    }

    .results-display {
      background: rgba(8,15,35,0.9);
      border-radius: 10px;
      padding: 1.5rem;
      margin: 1.5rem 0;
      border: 1px solid #2d4a7a;
    }

    .result-item {
      background: rgba(15,25,55,0.6);
      border-radius: 8px;
      padding: 1rem;
      margin: 0.75rem 0;
      border-left: 3px solid #18e0e6;
    }

    .result-label {
      color: #4a9eff;
      font-weight: 600;
      font-size: 0.9rem;
      margin-bottom: 0.25rem;
    }

    .result-value {
      color: #18e0e6;
      font-size: 1.2rem;
      font-weight: bold;
      font-family: 'Courier New', monospace;
    }

    .comparison-results {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 1.5rem;
      margin: 1.5rem 0;
    }

    .comparison-card {
      background: rgba(15,25,55,0.6);
      border: 1px solid #4a9eff;
      border-radius: 10px;
      padding: 1.5rem;
    }

    .comparison-card h4 {
      color: #18e0e6;
      margin-bottom: 1rem;
      font-size: 1.05rem;
    }

    .comparison-item {
      color: #b8d4ff;
      line-height: 1.8;
      margin: 0.5rem 0;
    }

    .comparison-item strong {
      color: #18e0e6;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      background: rgba(8,15,35,0.9);
      border-radius: 10px;
      overflow: hidden;
      margin: 1rem 0;
    }

    th, td {
      padding: 1rem;
      text-align: left;
      border-bottom: 1px solid #2d4a7a;
      color: #b8d4ff;
    }

    th {
      background: rgba(24,224,230,0.15);
      color: #18e0e6;
      font-weight: 600;
    }

    tr:hover {
      background: rgba(24,224,230,0.08);
    }

    .alert {
      background: rgba(255,193,7,0.1);
      border: 1px solid #ffc107;
      color: #ffd54f;
      padding: 1rem;
      border-radius: 8px;
      margin: 1rem 0;
    }

    .alert.success {
      background: rgba(76,175,80,0.1);
      border: 1px solid #4caf50;
      color: #81c784;
    }

    .alert.error {
      background: rgba(244,67,54,0.1);
      border: 1px solid #f44336;
      color: #ef5350;
    }

    ul, ol {
      line-height: 1.9;
    }

    li {
      margin-bottom: 0.5rem;
    }

    @media (max-width: 1024px) {
  .comparison-results {
    grid-template-columns: 1fr !important;
  }
}

code {
  background: rgba(8,15,35,0.9);
  padding: 0.25rem 0.5rem;
  border-radius: 4px;
  color: #18e0e6;
  font-family: 'Courier New', monospace;
  font-size: 0.85rem;
}

.pseudocode {
  white-space: pre-wrap;
  word-break: break-word;
}

/* Better scrolling for step-by-step */
#stepByStep {
  scrollbar-width: thin;
  scrollbar-color: #18e0e6 rgba(8,15,35,0.9);
}

#stepByStep::-webkit-scrollbar {
  width: 8px;
}

#stepByStep::-webkit-scrollbar-track {
  background: rgba(8,15,35,0.9);
}

#stepByStep::-webkit-scrollbar-thumb {
  background: #18e0e6;
  border-radius: 4px;
}
  </style>
</head>
<body>
  <header>
    <nav class="navbar">
      <div class="logo">Statistics<span class="cyber">Cyber</span></div>
      <ul id="navLinks">
        <li><a href="index.html">Home</a></li>
        <li><a href="homework.html">Homework</a></li>
        <li><a href="about.html">About</a></li>
      </ul>
      <button class="nav-toggle" id="navToggle">&#9776;</button>
    </nav>
  </header>

  <main>
    <section class="hw-detail">
      <h1>Homework 6: Online Algorithms for Incremental Statistics</h1>
      <p class="subtle">Derive recurrence relationships and implement online algorithms for computing statistics incrementally. Analyze numerical stability advantages over batch algorithms.</p>

      <!-- PART A: Mathematical Theory -->
      <div class="hw-section">
        <h2 style="color: #18e0e6; margin-bottom: 1.5rem;">Part A ‚Äî Mathematical Theory: Recurrence Relations</h2>
        
        <div class="step-container">
          <div class="step-title">
            <span class="step-number">1</span>
            Introduction to Online Algorithms
          </div>
          <div class="explanation">
            <p><strong>Online algorithms</strong> compute statistics incrementally as new data arrives, without storing all historical data or recomputing from scratch. Unlike batch algorithms that require all data upfront, online algorithms maintain running statistics with constant memory overhead.</p>
            
            <p style="margin-top: 1rem;"><strong>Key advantages:</strong></p>
            <ul style="margin-left: 1.5rem; line-height: 1.8;">
              <li>Process streaming data in real-time</li>
              <li>Constant memory complexity \(\mathcal{O}(1)\)</li>
              <li>Single pass through data \(\mathcal{O}(n)\)</li>
              <li>Numerically stable (avoids catastrophic cancellation)</li>
              <li>Suitable for incremental updates</li>
              <li>No need to store raw data</li>
            </ul>
          </div>
        </div>

        <div class="step-container">
          <div class="step-title">
            <span class="step-number">2</span>
            Recurrence Relation for Arithmetic Mean
          </div>
          
          <div class="explanation">
            Derive the recurrence relationship that allows computing the mean incrementally as each new observation arrives.
          </div>

          <div class="math-formula">
            <div class="formula-title">Problem Setup:</div>
            <div class="formula-content">
              Given \(n-1\) observations with computed mean \(\bar{x}_{n-1}\), find the new mean \(\bar{x}_n\) when the \(n\)-th observation \(x_n\) arrives.
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Derivation:</div>
            <div class="formula-content">
              By definition of arithmetic mean:
              $$\bar{x}_{n-1} = \frac{1}{n-1} \sum_{i=1}^{n-1} x_i$$
              
              Thus:
              $$\sum_{i=1}^{n-1} x_i = (n-1) \bar{x}_{n-1}$$
              
              After observing \(x_n\):
              $$\bar{x}_n = \frac{1}{n} \sum_{i=1}^{n} x_i = \frac{1}{n} \left( \sum_{i=1}^{n-1} x_i + x_n \right)$$
              
              Substitute previous sum:
              $$\bar{x}_n = \frac{1}{n} \left( (n-1) \bar{x}_{n-1} + x_n \right)$$
              
              Expand:
              $$\bar{x}_n = \frac{n-1}{n} \bar{x}_{n-1} + \frac{1}{n} x_n$$
              
              <strong>Alternative form (incremental update):</strong>
              $$\bar{x}_n = \bar{x}_{n-1} + \frac{1}{n} (x_n - \bar{x}_{n-1})$$
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Recurrence Relation:</div>
            <div class="formula-content">
              $$\boxed{\bar{x}_n = \bar{x}_{n-1} + \frac{x_n - \bar{x}_{n-1}}{n}}$$
              
              Starting condition: \(\bar{x}_1 = x_1\)<br><br>
              Interpretation: The new mean is the old mean plus a fraction \(\frac{1}{n}\) of the prediction error \((x_n - \bar{x}_{n-1})\).
            </div>
          </div>

          <div class="comparison-box">
            <strong style="color: #81c784;">‚úì Computational Properties:</strong>
            <div class="pros">
              <ul style="margin-left: 1.5rem; line-height: 1.8;">
                <li><strong>Time Complexity:</strong> \(\mathcal{O}(1)\) per update</li>
                <li><strong>Space Complexity:</strong> \(\mathcal{O}(1)\) (only store current mean)</li>
                <li><strong>Numerical Stability:</strong> No accumulation of large numbers; subtraction is numerically stable</li>
                <li><strong>Precision:</strong> Maintains good precision for large \(n\)</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="step-container">
          <div class="step-title">
            <span class="step-number">3</span>
            Recurrence Relation for Variance
          </div>
          
          <div class="explanation">
            Derive Welford's algorithm: the recurrence relationship for computing variance incrementally. This is more complex than the mean and requires careful numerical handling.
          </div>

          <div class="math-formula">
            <div class="formula-title">Problem Setup:</div>
            <div class="formula-content">
              Given \(n-1\) observations with computed mean \(\bar{x}_{n-1}\) and sum of squared deviations \(M_{n-1} = \sum_{i=1}^{n-1} (x_i - \bar{x}_{n-1})^2\), find the new variance after observation \(x_n\) arrives.
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Definition of Variance:</div>
            <div class="formula-content">
              Sample variance:
              $$s_n^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x}_n)^2 = \frac{M_n}{n-1}$$
              
              Where \(M_n\) is the sum of squared deviations from the current mean.
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Welford's Recurrence Derivation:</div>
            <div class="formula-content">
              When we compute the new mean \(\bar{x}_n\), the sum of squared deviations changes. We need to relate \(M_n\) to \(M_{n-1}\).
              <br><br>
              <strong>Key insight:</strong> Use delta method to update deviations:
              $$\Delta = x_n - \bar{x}_{n-1}$$
              $$\Delta' = x_n - \bar{x}_n$$
              
              From the mean recurrence:
              $$x_n - \bar{x}_n = x_n - \left(\bar{x}_{n-1} + \frac{x_n - \bar{x}_{n-1}}{n}\right)$$
              $$= x_n - \bar{x}_{n-1} - \frac{x_n - \bar{x}_{n-1}}{n}$$
              $$= \frac{n-1}{n}(x_n - \bar{x}_{n-1}) = \frac{n-1}{n}\Delta$$
              
              <strong>Crucially:</strong>
              $$\bar{x}_n - \bar{x}_{n-1} = \frac{x_n - \bar{x}_{n-1}}{n} = \frac{\Delta}{n}$$
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Computing M_n:</div>
            <div class="formula-content">
              The new sum of squared deviations:
              $$M_n = \sum_{i=1}^{n} (x_i - \bar{x}_n)^2$$
              
              We can rewrite this using the relation:
              $$(x_i - \bar{x}_n) = (x_i - \bar{x}_{n-1}) - (\bar{x}_n - \bar{x}_{n-1})$$
              
              Therefore:
              $$M_n = \sum_{i=1}^{n} \left[(x_i - \bar{x}_{n-1}) - (\bar{x}_n - \bar{x}_{n-1})\right]^2$$
              
              Expand the square:
              $$M_n = \sum_{i=1}^{n} (x_i - \bar{x}_{n-1})^2 - 2(\bar{x}_n - \bar{x}_{n-1}) \sum_{i=1}^{n} (x_i - \bar{x}_{n-1}) + n(\bar{x}_n - \bar{x}_{n-1})^2$$
              
              The key observation: \(\sum_{i=1}^{n-1} (x_i - \bar{x}_{n-1}) = 0\) by definition of mean, so:
              $$\sum_{i=1}^{n} (x_i - \bar{x}_{n-1}) = x_n - \bar{x}_{n-1} = \Delta$$
              
              Also: \(\sum_{i=1}^{n} (x_i - \bar{x}_{n-1})^2 = M_{n-1} + (x_n - \bar{x}_{n-1})^2 = M_{n-1} + \Delta^2\)
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Welford's Recurrence:</div>
            <div class="formula-content">
              Substituting all terms:
              $$M_n = M_{n-1} + \Delta^2 - 2(\bar{x}_n - \bar{x}_{n-1}) \Delta + n(\bar{x}_n - \bar{x}_{n-1})^2$$
              
              Substitute \(\bar{x}_n - \bar{x}_{n-1} = \frac{\Delta}{n}\):
              $$M_n = M_{n-1} + \Delta^2 - 2 \cdot \frac{\Delta}{n} \cdot \Delta + n \cdot \left(\frac{\Delta}{n}\right)^2$$
              $$= M_{n-1} + \Delta^2 - \frac{2\Delta^2}{n} + \frac{\Delta^2}{n}$$
              $$= M_{n-1} + \Delta^2 - \frac{\Delta^2}{n}$$
              $$= M_{n-1} + \Delta^2 \left(1 - \frac{1}{n}\right)$$
              $$= M_{n-1} + \frac{n-1}{n}\Delta^2$$
              
              <strong>Equivalent form:</strong>
              $$M_n = M_{n-1} + (x_n - \bar{x}_{n-1})(x_n - \bar{x}_n)$$
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Welford's Complete Algorithm:</div>
            <div class="formula-content">
              Let \(\Delta = x_n - \bar{x}_{n-1}\) and \(\delta = x_n - \bar{x}_n\)
              <br><br>
              $$\boxed{\begin{align}
              \bar{x}_n &= \bar{x}_{n-1} + \frac{\Delta}{n}\\
              M_n &= M_{n-1} + \Delta \cdot \delta\\
              s_n^2 &= \frac{M_n}{n-1}
              \end{align}}$$
              
              Starting conditions: \(\bar{x}_1 = x_1\), \(M_1 = 0\)
              <br><br>
              This is numerically superior because it never computes \(\sum x_i^2 - \frac{(\sum x_i)^2}{n}\), which causes catastrophic cancellation.
            </div>
          </div>

          <div class="comparison-box">
            <strong style="color: #81c784;">‚úì Why Welford's is Superior:</strong>
            <div class="pros">
              <ul style="margin-left: 1.5rem; line-height: 1.8;">
                <li><strong>Avoids subtraction of large numbers:</strong> Never computes \(\sum x_i^2 - \frac{(\sum x_i)^2}{n}\)</li>
                <li><strong>Numerical stability:</strong> Maintains accuracy even for large \(n\) and large values</li>
                <li><strong>Single pass:</strong> Requires only one pass through data</li>
                <li><strong>Constant memory:</strong> Only stores \(\bar{x}_{n-1}\), \(M_{n-1}\), and \(n\)</li>
                <li><strong>Handles outliers well:</strong> Incremental corrections prevent error accumulation</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="step-container">
          <div class="step-title">
            <span class="step-number">4</span>
            Higher Moments: Skewness and Kurtosis
          </div>
          
          <div class="explanation">
            Extend Welford's algorithm to compute higher moments incrementally. This is useful for advanced statistical analysis.
          </div>

          <div class="math-formula">
            <div class="formula-title">Third Moment (for Skewness):</div>
            <div class="formula-content">
              Let \(M_3^{(n)} = \sum_{i=1}^{n} (x_i - \bar{x}_n)^3\)
              <br><br>
              Recurrence:
              $$M_3^{(n)} = M_3^{(n-1)} + \Delta^3 \left(1 - \frac{3}{n} + \frac{2}{n^2}\right) + 3\Delta M_2^{(n-1)} \left(\frac{1}{n} - \frac{1}{n^2}\right)$$
              
              Or more practically:
              $$\Delta' = \frac{\Delta}{n}$$
              $$M_3^{(n)} = M_3^{(n-1)} + \Delta((\Delta - \delta) \cdot \delta - M_2^{(n-1)} \Delta')$$
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Fourth Moment (for Kurtosis):</div>
            <div class="formula-content">
              Let \(M_4^{(n)} = \sum_{i=1}^{n} (x_i - \bar{x}_n)^4\)
              <br><br>
              $$\Delta' = \frac{\Delta}{n}$$
              $$\delta' = 1 - \frac{1}{n}$$
              $$M_4^{(n)} = M_4^{(n-1)} + \Delta((\Delta^2 - M_2^{(n-1)})\delta' - 4M_3^{(n-1)}\Delta' + M_2^{(n-1)} \Delta'^2)$$
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Standardized Moments:</div>
            <div class="formula-content">
              Skewness:
              $$\gamma_1 = \frac{M_3^{(n)}}{(M_2^{(n)})^{3/2}}$$
              
              Kurtosis (excess):
              $$\gamma_2 = \frac{M_4^{(n)}}{(M_2^{(n)})^2} - 3$$
            </div>
          </div>
        </div>

        <div class="step-container">
          <div class="step-title">
            <span class="step-number">5</span>
            Online Covariance and Correlation
          </div>
          
          <div class="explanation">
            For multivariate statistics, we need to compute covariance between variables incrementally.
          </div>

          <div class="math-formula">
            <div class="formula-title">Bivariate Case:</div>
            <div class="formula-content">
              Given two variables \(X\) and \(Y\), track:
              <ul>
                <li>\(\bar{x}_{n-1}, \bar{y}_{n-1}\): Running means</li>
                <li>\(M_{xx}^{(n-1)}, M_{yy}^{(n-1)}\): Sum of squared deviations (univariate)</li>
                <li>\(M_{xy}^{(n-1)}\): Sum of cross-deviations (covariance term)</li>
              </ul>
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Recurrence for Cross-Deviation:</div>
            <div class="formula-content">
              $$M_{xy}^{(n)} = M_{xy}^{(n-1)} + (x_n - \bar{x}_{n-1})(y_n - \bar{y}_n)$$
              
              Then covariance:
              $$\text{Cov}(X,Y) = \frac{M_{xy}^{(n)}}{n-1}$$
              
              And Pearson correlation:
              $$r = \frac{M_{xy}^{(n)}}{\sqrt{M_{xx}^{(n)} \cdot M_{yy}^{(n)}}}$$
            </div>
          </div>
        </div>
      </div>

      <!-- PART B: Pseudocode & Algorithms -->
      <div class="hw-section">
        <h2 style="color: #18e0e6; margin-bottom: 1.5rem;">Part B ‚Äî Algorithm Implementation & Pseudocode</h2>
        
        <div class="step-container">
          <div class="step-title">
            <span class="step-number">1</span>
            Online Mean Algorithm
          </div>

          <div class="pseudocode">
            <div class="pseudocode-title">Algorithm: ONLINE_MEAN</div>
            <div class="pseudocode-line"><span class="keyword">Input:</span> Stream of values \(x_1, x_2, \ldots, x_n\)</div>
            <div class="pseudocode-line"><span class="keyword">Output:</span> Sequence of means \(\bar{x}_1, \bar{x}_2, \ldots, \bar{x}_n\)</div>
            <div class="pseudocode-line"></div>
            <div class="pseudocode-line"><span class="keyword">Initialize:</span></div>
            <div class="pseudocode-line">&nbsp;&nbsp;mean ‚Üê 0</div>
            <div class="pseudocode-line"></div>
            <div class="pseudocode-line"><span class="keyword">For</span> n = 1 to N:</div>
            <div class="pseudocode-line">&nbsp;&nbsp;Read next value \(x_n\)</div>
            <div class="pseudocode-line">&nbsp;&nbsp;mean ‚Üê mean + (x‚Çô - mean) / n</div>
            <div class="pseudocode-line">&nbsp;&nbsp;Output mean</div>
            <div class="pseudocode-line"><span class="keyword">End For</span></div>
            <div class="pseudocode-line"></div>
            <div class="pseudocode-line"><span class="comment">// Time: O(1) per update; Total: O(n)</span></div>
            <div class="pseudocode-line"><span class="comment">// Space: O(1) for running statistics</span></div>
          </div>

          <div class="comparison-box">
            <strong>Complexity Analysis:</strong>
            <ul style="margin-left: 1.5rem; line-height: 1.8;">
              <li><strong>Time Complexity:</strong> \(\mathcal{O}(n)\) for \(n\) observations (constant \(\mathcal{O}(1)\) per update)</li>
              <li><strong>Space Complexity:</strong> \(\mathcal{O}(1)\) - only stores current mean and count</li>
              <li><strong>Operations per update:</strong> 2 arithmetic operations (subtraction, division)</li>
            </ul>
          </div>
        </div>

        <div class="step-container">
          <div class="step-title">
            <span class="step-number">2</span>
            Welford's Algorithm for Mean & Variance
          </div>

          <div class="pseudocode">
            <div class="pseudocode-title">Algorithm: WELFORD_MEAN_VARIANCE</div>
            <div class="pseudocode-line"><span class="keyword">Input:</span> Stream of values \(x_1, x_2, \ldots, x_n\)</div>
            <div class="pseudocode-line"><span class="keyword">Output:</span> Mean and Variance</div>
            <div class="pseudocode-line"></div>
            <div class="pseudocode-line"><span class="keyword">Initialize:</span></div>
            <div class="pseudocode-line">&nbsp;&nbsp;mean ‚Üê 0</div>
            <div class="pseudocode-line">&nbsp;&nbsp;M2 ‚Üê 0 <span class="comment">// sum of squared deviations</span></div>
            <div class="pseudocode-line"></div>
            <div class="pseudocode-line"><span class="keyword">For</span> n = 1 to N:</div>
            <div class="pseudocode-line">&nbsp;&nbsp;Read next value \(x_n\)</div>
            <div class="pseudocode-line">&nbsp;&nbsp;delta ‚Üê x‚Çô - mean</div>
            <div class="pseudocode-line">&nbsp;&nbsp;mean ‚Üê mean + delta / n</div>
            <div class="pseudocode-line">&nbsp;&nbsp;delta2 ‚Üê x‚Çô - mean</div>
            <div class="pseudocode-line">&nbsp;&nbsp;M2 ‚Üê M2 + delta √ó delta2</div>
            <div class="pseudocode-line">&nbsp;&nbsp;variance ‚Üê M2 / (n - 1)</div>
            <div class="pseudocode-line"><span class="keyword">End For</span></div>
            <div class="pseudocode-line"></div>
            <div class="pseudocode-line"><span class="comment">// Time: O(1) per update; Total: O(n)</span></div>
            <div class="pseudocode-line"><span class="comment">// Space: O(1) for two accumulators</span></div>
          </div>

          <div class="comparison-box">
            <strong>Complexity Analysis:</strong>
            <ul style="margin-left: 1.5rem; line-height: 1.8;">
              <li><strong>Time Complexity:</strong> \(\mathcal{O}(n)\) for \(n\) observations</li>
              <li><strong>Space Complexity:</strong> \(\mathcal{O}(1)\) - only stores mean, M2, and count</li>
              <li><strong>Operations per update:</strong> 5 arithmetic operations</li>
              <li><strong>Memory Usage:</strong> 3 floating-point numbers</li>
            </ul>
          </div>
        </div>

        <div class="step-container">
          <div class="step-title">
            <span class="step-number">3</span>
            Extended Algorithm: Mean, Variance, Skewness, Kurtosis
          </div>

          <div class="pseudocode">
            <div class="pseudocode-title">Algorithm: WELFORD_MOMENTS</div>
            <div class="pseudocode-line"><span class="keyword">Input:</span> Stream of values \(x_1, x_2, \ldots, x_n\)</div>
            <div class="pseudocode-line"><span class="keyword">Output:</span> Mean, Variance, Skewness, Kurtosis</div>
            <div class="pseudocode-line"></div>
            <div class="pseudocode-line"><span class="keyword">Initialize:</span></div>
            <div class="pseudocode-line">&nbsp;&nbsp;mean ‚Üê 0</div>
            <div class="pseudocode-line">&nbsp;&nbsp;M2, M3, M4 ‚Üê 0 <span class="comment">// central moments</span></div>
            <div class="pseudocode-line"></div>
            <div class="pseudocode-line"><span class="keyword">For</span> n = 1 to N:</div>
            <div class="pseudocode-line">&nbsp;&nbsp;Read next value \(x_n\)</div>
            <div class="pseudocode-line">&nbsp;&nbsp;delta ‚Üê x‚Çô - mean</div>
            <div class="pseudocode-line">&nbsp;&nbsp;mean ‚Üê mean + delta / n</div>
            <div class="pseudocode-line">&nbsp;&nbsp;delta2 ‚Üê x‚Çô - mean</div>
            <div class="pseudocode-line">&nbsp;&nbsp;delta_n ‚Üê delta / n</div>
            <div class="pseudocode-line">&nbsp;&nbsp;delta_n2 ‚Üê delta_n √ó delta_n</div>
            <div class="pseudocode-line"></div>
            <div class="pseudocode-line">&nbsp;&nbsp;M4 ‚Üê M4 + delta_n2 √ó delta_n2 √ó (n-1) √ó (n¬≤ - 3n + 3) + 6 √ó delta_n2 √ó M2 - 4 √ó delta_n √ó M3</div>
            <div class="pseudocode-line">&nbsp;&nbsp;M3 ‚Üê M3 + delta_n2 √ó delta √ó (n-2) - 3 √ó delta_n √ó M2</div>
            <div class="pseudocode-line">&nbsp;&nbsp;M2 ‚Üê M2 + delta √ó delta2</div>
            <div class="pseudocode-line"><span class="keyword">End For</span></div>
            <div class="pseudocode-line"></div>
            <div class="pseudocode-line"><span class="keyword">Compute:</span></div>
            <div class="pseudocode-line">&nbsp;&nbsp;variance ‚Üê M2 / (n - 1)</div>
            <div class="pseudocode-line">&nbsp;&nbsp;skewness ‚Üê M3 / (M2)^(3/2)</div>
            <div class="pseudocode-line">&nbsp;&nbsp;kurtosis ‚Üê M4 / (M2)¬≤ - 3</div>
          </div>

          <div class="comparison-box">
            <strong>Complexity Analysis:</strong>
            <ul style="margin-left: 1.5rem; line-height: 1.8;">
              <li><strong>Time Complexity:</strong> \(\mathcal{O}(n)\) for \(n\) observations, \(\mathcal{O}(1)\) per update</li>
              <li><strong>Space Complexity:</strong> \(\mathcal{O}(1)\) - only 4 moment accumulators</li>
              <li><strong>Operations per update:</strong> ~15 arithmetic operations</li>
              <li><strong>Numerical Stability:</strong> Excellent for all 4 moments</li>
            </ul>
          </div>
        </div>
      </div>

      <!-- PART C: Numerical Stability Analysis -->
      <div class="hw-section">
        <h2 style="color: #18e0e6; margin-bottom: 1.5rem;">Part C ‚Äî Numerical Stability & Error Analysis</h2>
        
        <div class="step-container">
          <div class="step-title">
            <span class="step-number">1</span>
            Catastrophic Cancellation in Batch Algorithms
          </div>
          
          <div class="explanation">
            The traditional batch formula for variance suffers from catastrophic cancellation, a fundamental numerical stability problem.
          </div>

          <div class="math-formula">
            <div class="formula-title">Naive Batch Variance Formula:</div>
            <div class="formula-content">
              $$s^2 = \frac{1}{n-1} \left( \sum_{i=1}^{n} x_i^2 - \frac{(\sum_{i=1}^{n} x_i)^2}{n} \right)$$
              
              This formula is susceptible to catastrophic cancellation because:
              <ul>
                <li>\(\sum x_i^2\) can be very large</li>
                <li>\(\frac{(\sum x_i)^2}{n}\) is also very large</li>
                <li>When both are large and nearly equal, their difference loses precision</li>
              </ul>
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Numerical Example:</div>
            <div class="formula-content">
              Data: \(x = [10^8, 10^8 + 1, 10^8 + 2]\)<br><br>
              True variance: \(s^2 = 1.0\)
              <br><br>
              <strong>Using batch formula (single precision, 6 significant digits):</strong>
              <ul>
                <li>\(\sum x_i = 3 \times 10^8 + 3\) ‚Üí rounds to \(3 \times 10^8\)</li>
                <li>\(\sum x_i^2 = (10^8)^2 \times 3 + 2 \times 10^8 + 5\) ‚âà \(3 \times 10^{16}\)</li>
                <li>\(\frac{(\sum x_i)^2}{n} = \frac{9 \times 10^{16}}{3}\) = \(3 \times 10^{16}\)</li>
                <li>Difference: \(3 \times 10^{16} - 3 \times 10^{16}\) = \(0\) (or garbage due to rounding)</li>
                <li>Computed variance: <strong>0 or wildly incorrect</strong></li>
              </ul>
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Why Welford's Avoids This:</div>
            <div class="formula-content">
              Welford's algorithm never computes \(\sum x_i^2\) or the large cancellation. Instead:
              <ul>
                <li>Maintains running mean \(\bar{x}\) (moderate size)</li>
                <li>Computes \(\delta = x_n - \bar{x}\) (small quantity)</li>
                <li>Updates \(M_n = M_{n-1} + \delta \times \delta'\) (stable subtraction)</li>
              </ul>
              
              With Welford's algorithm on the same data:
              <ul>
                <li>\(\delta_1 = 10^8 - 10^8 = 0\)</li>
                <li>\(\delta_2 = (10^8 + 1) - 10^8 = 1\) ‚úì</li>
                <li>\(\delta_3 = (10^8 + 2) - 10^8 = 2\) ‚úì</li>
                <li>Computed variance: <strong>1.0 (correct)</strong></li>
              </ul>
            </div>
          </div>

          <div class="comparison-box">
            <div class="pros">
              <strong style="color: #81c784;">‚úì Welford's Advantages:</strong>
              <ul style="margin-left: 1.5rem; line-height: 1.8;">
                <li>Never subtracts large numbers</li>
                <li>Always operates on manageable deltas</li>
                <li>No accumulated rounding errors</li>
                <li>Works with extreme value magnitudes</li>
              </ul>
            </div>
            <div class="cons">
              <strong style="color: #ef5350;">‚úó Batch Formula Issues:</strong>
              <ul style="margin-left: 1.5rem; line-height: 1.8;">
                <li>Subtracts two very large nearly-equal numbers</li>
                <li>Cancellation eliminates all significant digits</li>
                <li>Fails for data with large magnitudes</li>
                <li>Requires careful scaling/shifting (cumbersome)</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="step-container">
          <div class="step-title">
            <span class="step-number">2</span>
            Error Propagation Analysis
          </div>
          
          <div class="explanation">
            Analyze how computational errors accumulate in batch vs online algorithms.
          </div>

          <div class="math-formula">
            <div class="formula-title">Rounding Error Model:</div>
            <div class="formula-content">
              For floating-point arithmetic with machine epsilon \(\varepsilon\):
              <br><br>
              <strong>Batch Algorithm Error:</strong>
              $$\text{Error}_{batch} \approx \mathcal{O}(n \varepsilon (x_{\max}^2))$$
              
              Because:
              <ul>
                <li>Accumulates errors from \(n\) multiplications</li>
                <li>Propagates through large sum \(\sum x_i^2\)</li>
                <li>Amplified by cancellation: error ‚âà \(\frac{\text{rounding error}}{\text{difference}}\)</li>
              </ul>
              
              <strong>Welford's Algorithm Error:</strong>
              $$\text{Error}_{Welford} \approx \mathcal{O}(n \varepsilon)$$
              
              Because:
              <ul>
                <li>Only accumulated deltas (magnitude bounded)</li>
                <li>No amplification from cancellation</li>
                <li>Error scale-independent of data magnitude</li>
              </ul>
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Worst-Case Error Bounds:</div>
            <div class="formula-content">
              Batch: \(|\text{computed} - \text{true}| \lesssim \mathcal{O}(n^2 \varepsilon \cdot \text{scale}^2)\)<br>
              Welford: \(|\text{computed} - \text{true}| \lesssim \mathcal{O}(n \varepsilon \cdot \text{scale})\)<br><br>
              
              For typical floating-point (double precision \(\varepsilon \approx 10^{-16}\)):
              <ul>
                <li><strong>Batch:</strong> Error grows quadratically with \(n\) and quadratically with data scale</li>
                <li><strong>Welford:</strong> Error grows linearly with \(n\) and linearly with data scale</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="step-container">
          <div class="step-title">
            <span class="step-number">3</span>
            Overflow and Underflow Prevention
          </div>
          
          <div class="explanation">
            Discuss how online algorithms naturally prevent overflow/underflow problems.
          </div>

          <div class="math-formula">
            <div class="formula-title">Overflow Scenarios:</div>
            <div class="formula-content">
              <strong>Batch Algorithm:</strong>
              <ul>
                <li>\(\sum x_i^2\) can overflow if individual \(x_i^2\) are large</li>
                <li>E.g., with \(n = 1000\) data points of magnitude \(10^{100}\): \(\sum x_i^2 \approx 10^{203}\) ‚Üí overflow</li>
                <li>Requires manual scaling: divide all data by 10^50 before computation (error-prone)</li>
              </ul>
              
              <strong>Welford's Algorithm:</strong>
              <ul>
                <li>\(\delta = x_n - \bar{x}\) remains bounded: \(|\delta| \leq 2 \times 10^{100}\)</li>
                <li>\(\delta \times \delta'\) also remains manageable</li>
                <li>M2 grows linearly, not quadratically in data magnitude</li>
                <li>No overflow unless result itself overflows (expected)</li>
              </ul>
            </div>
          </div>

          <div class="math-formula">
            <div class="formula-title">Underflow Scenarios:</div>
            <div class="formula-content">
              <strong>Batch Algorithm:</strong>
              <ul>
                <li>With very small data (\(x_i \approx 10^{-100}\)): \(x_i^2 \approx 10^{-200}\) ‚Üí underflow</li>
                <li>Variance computation loses all significance</li>
              </ul>
              
              <strong>Welford's Algorithm:</strong>
              <ul>
                <li>\(\delta = x_n - \bar{x}\) maintains precision even for small data</li>
                <li>Deltas capture relative changes, not absolute magnitudes</li>
                <li>Works reliably across extreme ranges (e.g., \(10^{-100}\) to \(10^{100}\))</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="step-container">
          <div class="step-title">
            <span class="step-number">4</span>
            Comparative Summary: Batch vs Online
          </div>

          <table>
            <thead>
              <tr>
                <th>Property</th>
                <th>Batch Algorithm</th>
                <th>Online (Welford)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Time Complexity</strong></td>
                <td>\(\mathcal{O}(n)\)</td>
                <td>\(\mathcal{O}(n)\) (constant factor 2-3√ó better)</td>
              </tr>
              <tr>
                <td><strong>Space Complexity</strong></td>
                <td>\(\mathcal{O}(n)\) (stores all data)</td>
                <td>\(\mathcal{O}(1)\)</td>
              </tr>
              <tr>
                <td><strong>Numerical Stability</strong></td>
                <td>Poor (catastrophic cancellation)</td>
                <td>Excellent</td>
              </tr>
              <tr>
                <td><strong>Error Growth</strong></td>
                <td>\(\mathcal{O}(n^2 \varepsilon)\)</td>
                <td>\(\mathcal{O}(n \varepsilon)\)</td>
              </tr>
              <tr>
                <td><strong>Overflow Risk</strong></td>
                <td>High (\(\sum x_i^2\))</td>
                <td>Very Low (deltas)</td>
              </tr>
              <tr>
                <td><strong>Streaming Data</strong></td>
                <td>Impossible (needs all data)</td>
                <td>Ideal (incremental)</td>
              </tr>
              <tr>
                <td><strong>Memory for Large n</strong></td>
                <td>Prohibitive</td>
                <td>Constant regardless of \(n\)</td>
              </tr>
              <tr>
                <td><strong>Implementation Complexity</strong></td>
                <td>Simple</td>
                <td>Moderate (but well-understood)</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>

      <!-- PART D: Interactive Tool -->
      <div class="hw-section">
        <h2 style="color: #18e0e6; margin-bottom: 1.5rem;">Part D ‚Äî Interactive Statistics Calculator</h2>
        
        <div class="interactive-tool">
                      <div class="tool-title">üìä Main Calculator: Online vs Batch Statistics</div>
            
            <div style="display: grid; grid-template-columns: 2fr 1fr; gap: 1.5rem; margin-bottom: 1.5rem;">
              <div>
                <div class="input-group">
                  <label for="dataInput"><strong>Enter Data</strong> (comma or space separated):</label>
                  <textarea id="dataInput" placeholder="Example: 1.5, 2.3, 3.1, 4.7, 5.2">1.5, 2.3, 3.1, 4.7, 5.2</textarea>
                </div>
              </div>
              
              <div>
                <div class="input-group">
                  <label for="scaleFactor"><strong>Scale Factor</strong>:</label>
                  <input type="number" id="scaleFactor" value="1" step="0.1" min="0.0001" max="1e12" placeholder="1">
                  <small style="color: #4a9eff; margin-top: 0.25rem; display: block;">Multiply all data by this factor</small>
                </div>
              </div>
            </div>

            <div class="btn-group">
              <button class="btn" onclick="computeStatistics()">üìà Compute Statistics</button>
              <button class="btn secondary" onclick="generateRandomData()">üé≤ Random Data</button>
              <button class="btn secondary" onclick="generateExtremeData()">‚ö†Ô∏è Extreme Values</button>
              <button class="btn danger" onclick="clearResults()">üóëÔ∏è Clear All</button>
            </div>

            <div id="results"></div>
          </div>

          <div class="tool-section">
               <div class="tool-title">üîÑ Step-by-Step: Welford's Algorithm Visualization</div>
            
            <div style="background: rgba(8,15,35,0.6); border-radius: 8px; padding: 1rem; margin: 1rem 0;">
              <p style="color: #b8d4ff; font-size: 0.9rem; margin-bottom: 1rem;">
                Shows each iteration of Welford's online algorithm, tracking how mean and M2 (sum of squared deviations) evolve incrementally.
              </p>
              <div id="stepByStep" style="max-height: 500px; overflow-y: auto;"></div>
            </div>
          </div>

          <div class="tool-section">
             <div class="tool-title">üß™ Numerical Stability Test: Batch vs Online</div>
            
            <div style="background: rgba(8,15,35,0.6); border-radius: 8px; padding: 1rem; margin: 1rem 0;">
              <p style="color: #b8d4ff; font-size: 0.9rem; margin-bottom: 1rem;">
                Tests both algorithms with data at extreme magnitudes. Online algorithms maintain accuracy; batch algorithms may suffer from catastrophic cancellation.
              </p>
              
              <div class="input-group">
                <label for="magOrder"><strong>Select Data Magnitude:</strong></label>
                <select id="magOrder" style="width: 100%; padding: 0.75rem; border-radius: 8px; border: 1px solid #3a5a8a; background: #0f1937; color: #e9f2ff;">
                  <option value="100">10¬≤ = 100 (moderate)</option>
                  <option value="1000">10¬≥ = 1,000</option>
                  <option value="1e6">10‚Å∂ = 1,000,000 (large)</option>
                  <option value="1e9">10‚Åπ = 1 billion</option>
                  <option value="1e12">10¬π¬≤ = 1 trillion (very large)</option>
                  <option value="1e-6">10‚Åª‚Å∂ = 0.000001 (very small)</option>
                  <option value="1e-9">10‚Åª‚Åπ = 0.000000001 (tiny)</option>
                  <option value="1e-12">10‚Åª¬π¬≤ = extreme underflow</option>
                </select>
              </div>

              <div class="btn-group">
                <button class="btn secondary" onclick="testNumericalStability()">üß™ Run Stability Test</button>
              </div>
            </div>

            <div id="stabilityResults"></div>
          </div>
        </div>
      </div>

      <div class="centered">
        <a href="homework.html" class="btn">‚Üê Back to Homework List</a>
      </div>
    </section>
  </main>

  <footer>
    <span>&copy; 2025 Lorenzo Ciafrelli | MS Cybersecurity, Sapienza University of Rome</span>
  </footer>

  <script src="script.js"></script>
  <script src="hw6.js"></script>
</body>
</html>
